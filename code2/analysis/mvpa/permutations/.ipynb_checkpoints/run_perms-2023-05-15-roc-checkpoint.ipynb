{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "intimate-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook run_perms-2023-05-15-roc.ipynb to python\n",
      "[NbConvertApp] Writing 20725 bytes to run_perms-2023-05-15-roc.py\n"
     ]
    }
   ],
   "source": [
    "# python resample.py $IMAGE_TO_RESAMPLE $REFERENCE_IMAGE\n",
    "#!jupyter nbconvert run_perms-2023-05-15-roc.ipynb --to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "local-objective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ~~~ script updates ~~~\\ncopied from 5-11\\n5-12: cleaned directory structure\\ncopied from 5-13\\n- implements roc\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ~~~ script updates ~~~\n",
    "copied from 5-11\n",
    "5-12: cleaned directory structure\n",
    "copied from 5-13\n",
    "- implements roc\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shared-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "from nilearn.input_data import NiftiMasker , MultiNiftiMasker, NiftiLabelsMasker\n",
    "import nilearn as nil\n",
    "import numpy as np \n",
    "import os\n",
    "import os.path\n",
    "import scipy.io\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.masking import compute_epi_mask\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import sys  \n",
    "import random\n",
    "# import logging\n",
    "\n",
    "import deepdish as dd\n",
    "import numpy as np\n",
    "\n",
    "import brainiak.eventseg.event\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, zscore, pearsonr\n",
    "from scipy.signal import gaussian, convolve\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\"\"\"\n",
    "from utils import sherlock_h5_data\n",
    "\n",
    "if not os.path.exists(sherlock_h5_data):\n",
    "    os.makedirs(sherlock_h5_data)\n",
    "    print('Make dir: ', sherlock_h5_data)\n",
    "else: \n",
    "    print('Data path exists')\n",
    "    \n",
    "from utils import sherlock_dir\n",
    "\"\"\"\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "from brainiak import image, io\n",
    "from scipy.stats import stats\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from brainiak import image, io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import pandas as pd\n",
    "# Import machine learning libraries\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import sem\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statistics\n",
    "# Visualize it as an ROI\n",
    "from nilearn.plotting import plot_roi\n",
    "#plot_roi(x)\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img,index_img\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_to_img\n",
    "from scipy.spatial.distance import squareform\n",
    "# Visualize it as an ROI\n",
    "from nilearn.plotting import plot_roi\n",
    "import statsmodels.stats.multitest as st\n",
    "from nilearn import connectome\n",
    "from nilearn import image\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from nilearn import input_data\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "from nilearn.masking import apply_mask\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-indonesia",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "horizontal-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import label_lists, find_cond_index, org_bold_data,load_epi_data, load_roi_mask, intersect_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "taken-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_roi_mask(rois_dir, ROI_name, space):\n",
    "    if space == \"MNI\":\n",
    "        maskdir = os.path.join(rois_dir)    \n",
    "        print(\"expected shape: 78, 93,65\")\n",
    "    elif space == \"T1\":\n",
    "        maskdir = os.path.join(rois_dir+ \"/T1\")\n",
    "        print(\"expected shape: 56, 72,53\")\n",
    "    else:\n",
    "        print(\"wrong mask input. check this function\")\n",
    "    # load the mask\n",
    "    maskfile = os.path.join(maskdir, \"%s.nii\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"mask shape: \", mask.shape)\n",
    "    print(\"Loaded %s mask\" % (ROI_name))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "productive-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_groups(X,y, groups, norm):\n",
    "    \"\"\"\n",
    "    sub_out is an index of the subject you'd like to leave out\n",
    "    \"\"\"\n",
    "    logo = LeaveOneGroupOut()\n",
    "    logo.get_n_splits(X, y, groups)\n",
    "    clf_score = np.array([])\n",
    "    inner_clf_score = np.array([])\n",
    "    C_best = []\n",
    "    #print(\"GROUPS:\", logo.get_n_splits(groups=groups))\n",
    "    # Train vs Test\n",
    "    for train_index, test_index in logo.split(X,y, groups):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #print(X_train.shape)\n",
    "        #print(y_train)\n",
    "\n",
    "        ## Further split into training groups for grid search\n",
    "        logo2 = LeaveOneGroupOut()\n",
    "        logo2.get_n_splits(X_train, y_train, groups[train_index])\n",
    "        #print(\"GROUPS-2:\", logo2.get_n_splits(groups=groups[train_index]))\n",
    "        # Normalize data   \n",
    "        if norm:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        # For the present train vs test set, cross validate\n",
    "        parameters = {'C':[0.00001, 0.0001, 0.01, 0.1, 1, 10]}\n",
    "        inner_clf = GridSearchCV(\n",
    "            SVC(kernel='linear'),\n",
    "            parameters,\n",
    "            cv=logo2.split(X_train, y_train, groups[train_index]),\n",
    "            return_train_score=True)\n",
    "        inner_clf.fit(X_train, y_train)\n",
    "        #print(\"inner score: \", inner_clf.score(X_train, y_train))\n",
    "        inner_clf_score = np.hstack((inner_clf_score, inner_clf.score(X_train, y_train)))\n",
    "\n",
    "        # Find the best hyperparameter\n",
    "        C_best_i = inner_clf.best_params_['C']\n",
    "        C_best.append(C_best_i)\n",
    "\n",
    "        # Train the classifier with the best hyperparameter using training and validation set\n",
    "        classifier = SVC(kernel=\"linear\", C=C_best_i)\n",
    "        clf = classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Test the classifier\n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score = np.hstack((clf_score, score))\n",
    "        #print(\"Outer score: \", score)\n",
    "\n",
    "    #print ('Inner loop classification accuracy:', np.mean(inner_clf_score))\n",
    "    #print('best c: ', C_best_i)\n",
    "    #print ('Overall accuracy: ', np.mean(clf_score))\n",
    "    return np.mean(clf_score), np.mean(inner_clf_score)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-thread",
   "metadata": {},
   "source": [
    "# New classifier functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-woman",
   "metadata": {},
   "source": [
    "## Leave one out with SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fiscal-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_leaveOneGroupOut(X, y, groups, norm):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    logo.get_n_splits(X, y, groups)\n",
    "    clf_score = np.array([])\n",
    "    inner_clf_score = np.array([])\n",
    "    C_best = []\n",
    "    print(\"GROUPS:\", logo.get_n_splits(groups=groups))\n",
    "\n",
    "    # Train vs Test\n",
    "    for train_index, test_index in logo.split(X,y, groups):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        ## Further split into training groups for grid search\n",
    "        logo2 = LeaveOneGroupOut()\n",
    "        logo2.get_n_splits(X_train, y_train, groups[train_index])\n",
    "        print(\"GROUPS-2:\", logo2.get_n_splits(groups=groups[train_index]))\n",
    "\n",
    "        # Normalize data   \n",
    "        if norm:\n",
    "            X_train = np.array(X_train)\n",
    "            X_test = np.array(X_test)\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        # For the present train vs test set, cross validate\n",
    "        parameters = {'C':[0.00001, 0.0001, 0.01, 0.1, 1, 10]}\n",
    "        inner_clf = GridSearchCV(\n",
    "            SGDClassifier(loss=\"hinge\"),\n",
    "            parameters,\n",
    "            cv=logo2.split(X_train, y_train, groups[train_index]),\n",
    "            return_train_score=True)\n",
    "        inner_clf.fit(X_train, y_train)\n",
    "        print(\"inner score: \", inner_clf.score(X_train, y_train))\n",
    "        inner_clf_score = np.hstack((inner_clf_score, inner_clf.score(X_train, y_train)))\n",
    "\n",
    "        # Find the best hyperparameter\n",
    "        C_best_i = inner_clf.best_params_['C']\n",
    "        C_best.append(C_best_i)\n",
    "\n",
    "        # Train the classifier with the best hyperparameter using training and validation set\n",
    "        classifier = SGDClassifier(loss=\"hinge\", C=C_best_i)\n",
    "        clf = classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Test the classifier\n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score = np.hstack((clf_score, score))\n",
    "        print(\"Outer score: \", score)\n",
    "\n",
    "    return np.mean(clf_score), np.mean(inner_clf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-techno",
   "metadata": {},
   "source": [
    "## GroupKFold classifier, n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_GroupKFold(X, y, groups, norm):\n",
    "    group_kfold = GroupKFold()\n",
    "    group_kfold.get_n_splits(X, y, groups)\n",
    "    clf_score = np.array([])\n",
    "    inner_clf_score = np.array([])\n",
    "    C_best = []\n",
    "    #print(\"GROUPS:\", group_kfold.get_n_splits(groups=groups))\n",
    "\n",
    "    # Train vs Test\n",
    "    for train_index, test_index in group_kfold.split(X,y, groups):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        ## Further split into training groups for grid search\n",
    "        group_kfold2 = GroupKFold()\n",
    "        group_kfold2.get_n_splits(X_train, y_train, groups[train_index])\n",
    "        #print(\"GROUPS-2:\", group_kfold2.get_n_splits(groups=groups[train_index]))\n",
    "\n",
    "        # Normalize data   \n",
    "        if norm:\n",
    "            X_train = np.array(X_train)\n",
    "            X_test = np.array(X_test)\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        # For the present train vs test set, cross validate\n",
    "        parameters = {'C':[0.00001, 0.0001, 0.01, 0.1, 1, 10]}\n",
    "        inner_clf = GridSearchCV(\n",
    "            SVC(kernel=\"linear\", class_weight='balanced'),\n",
    "            parameters,\n",
    "            cv=group_kfold2.split(X_train, y_train, groups[train_index]),\n",
    "            return_train_score=True)\n",
    "        inner_clf.fit(X_train, y_train)\n",
    "        print(\"inner score: \", inner_clf.score(X_train, y_train))\n",
    "        inner_clf_score = np.hstack((inner_clf_score, inner_clf.score(X_train, y_train)))\n",
    "\n",
    "        # Find the best hyperparameter\n",
    "        C_best_i = inner_clf.best_params_['C']\n",
    "        C_best.append(C_best_i)\n",
    "\n",
    "        # Train the classifier with the best hyperparameter using training and validation set\n",
    "        classifier = SVC(kernel='linear', C=C_best_i, class_weight='balanced')\n",
    "        clf = classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Test the classifier\n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score = np.hstack((clf_score, score))\n",
    "        print(\"Outer score: \", score)\n",
    "\n",
    "    return np.mean(clf_score), np.mean(inner_clf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_GroupKFold_roc(X, y, groups, n_splits, norm=True):\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    group_kfold.get_n_splits(X, y, groups)\n",
    "    clf_score = np.array([])\n",
    "    roc_score = np.array([])\n",
    "    inner_clf_score = np.array([])\n",
    "    C_best = []\n",
    "    #print(\"GROUPS:\", group_kfold.get_n_splits(groups=groups))\n",
    "\n",
    "    ## Iterate through each fold ## \n",
    "    for i, (train_index, test_index) in enumerate(group_kfold.split(X,y, groups)):\n",
    "        print(f'\\n FOLD {i}')\n",
    "        ## split into train / test sets \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        print(f' Train indices count: {len(np.unique(groups[train_index]))}')\n",
    "        print(f' Test indices count: {len(np.unique(groups[test_index]))}')\n",
    "        print(f'percent 1s of Y set {(np.sum(y[test_index])) / len(y[test_index])}')\n",
    "        \n",
    "        ## convert y's to arrays ## \n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        ## Further split into training groups for grid search\n",
    "        group_kfold2 = GroupKFold(n_splits=n_splits)\n",
    "        group_kfold2.get_n_splits(X_train, y_train, groups[train_index])\n",
    "\n",
    "        # Normalize data   \n",
    "        if norm:\n",
    "            X_train = np.array(X_train)\n",
    "            X_test = np.array(X_test)\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        # For the folds train vs test set, cross validate\n",
    "        #smaller values specify stronger regularization.\n",
    "        parameters = {'C':[0.00001, 0.0001, 0.01, 0.1, 1, 10]}\n",
    "        ## Define model ##\n",
    "        inner_clf = GridSearchCV(\n",
    "            SVC(kernel=\"linear\", class_weight = 'balanced'),\n",
    "            parameters,\n",
    "            cv=group_kfold2.split(X_train, y_train, groups[train_index]),\n",
    "            scoring = 'roc_auc',\n",
    "            return_train_score=True)\n",
    "        ## Run the model on the current folds training data - this will run nested cross val ## \n",
    "        inner_clf.fit(X_train, y_train, groups[train_index])\n",
    "\n",
    "        #print('train:',inner_clf.predict(X_train))\n",
    "        print(\"BEST C:\", inner_clf.best_params_['C'])\n",
    "        print(\"inner score: \", inner_clf.score(X_train, y_train))\n",
    "        print(f'inner roc: {roc_auc_score(y_train, inner_clf.predict(X_train))}')\n",
    "        inner_clf_score = np.hstack((inner_clf_score, inner_clf.score(X_train, y_train)))\n",
    "        \n",
    "        \n",
    "        # Find the best hyperparameter\n",
    "        C_best_i = inner_clf.best_params_['C']\n",
    "        C_best.append(C_best_i)\n",
    "\n",
    "        # Train the classifier with the best hyperparameter using entire train set \n",
    "        classifier = SVC(kernel='linear', C=C_best_i, class_weight='balanced')\n",
    "        clf = classifier.fit(X_train, y_train, groups[train_index])\n",
    "        \n",
    "        # Test the classifier on held out test dataset \n",
    "        score = clf.score(X_test, y_test)\n",
    "        clf_score = np.hstack((clf_score, score))\n",
    "        print('test predictions:', classifier.predict(X_test))\n",
    "        \n",
    "        roc = roc_auc_score(y_test, classifier.predict(X_test))\n",
    "        roc_score = np.hstack((roc_score, roc))\n",
    "        print(\"Outer score: \", score, 'roc:', roc)\n",
    "\n",
    "    return np.mean(clf_score), clf_score, np.mean(inner_clf_score), np.mean(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "declared-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_perm(clf_fxn, X, y, groups, n_splits):  \n",
    "    print('begin perm')\n",
    "    #print(\"Before: \", label_data)\n",
    "    ## Shuffle TRs + classify\n",
    "    np.random.shuffle(y)\n",
    "    ## we only care about roc\n",
    "    classif_acc_outer, _, _, roc = clf_fxn(X,y, groups, n_splits)\n",
    "    print(classif_acc_outer, roc)\n",
    "    print('end perm', end='\\n')\n",
    "    return classif_acc_outer, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-geometry",
   "metadata": {},
   "source": [
    "# Run Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rural-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIf so, destroy \\nperm_results_*.npy\\nat\\n/jukebox/graziano/coolCatIsaac/ATM/code/analysis/bpress/mindy_mvpa/permutations'\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Do you want to reset the permuation array ??? ##\n",
    "\"\"\"\n",
    "If so, destroy \n",
    "perm_results_*.npy\n",
    "at\n",
    "/jukebox/graziano/coolCatIsaac/ATM/code/analysis/bpress/mindy_mvpa/permutations'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decreased-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#num_perm = int(sys.argv[1])\\n\\n\\n\\n# name of current analysis\\nanalysis = '%s_%s_%s_win%s' %(cond_a, cond_b, roi, window)\\n\\nX = activations[analysis]['X']\\ny = activations[analysis]['y']\\ngroups = activations[analysis]['groups']\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Slurm ##\n",
    "num_perm = int(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incorporated-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(974, 112)\n",
      "(974,)\n",
      "(974,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### iPython ## \n",
    "roi = 'dmPFC'\n",
    "window = '1'\n",
    "cond_a = 'SM'\n",
    "cond_b = 'SC'\n",
    "num_perm = 1\n",
    "\n",
    "# # name of current analysis\n",
    "analysis = '%s_%s_%s_win%s' %(cond_a, cond_b, roi, window)\n",
    "\n",
    "X = activations[analysis]['X']\n",
    "y = activations[analysis]['y']\n",
    "groups = activations[analysis]['groups']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(groups.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-violin",
   "metadata": {},
   "source": [
    "# start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-ivory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dependent-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory # \n",
    "# Top Directory\n",
    "top_dir = '/jukebox/graziano/coolCatIsaac/ATM/code/analysis/MVPA/final'\n",
    "act_dir = top_dir + '/activations'\n",
    "perm_dir = top_dir +'/permutations'\n",
    "perm_results = perm_dir + '/perm_results'\n",
    "acc_dir = top_dir + '/classification'\n",
    "\n",
    "\n",
    "\n",
    "# set analysis vars \n",
    "# set analysis vars \n",
    "date = '2023-06-06'\n",
    "norm = 'temp'\n",
    "act_dict_name = f'roi_activations_final_n28_{norm}norm_{date}'\n",
    "# perms \n",
    "perm_roc_name = f'perm_roc_{norm}norm_{date}'\n",
    "\n",
    "\n",
    "\n",
    "#load activation dictionary\n",
    "activations = np.load(os.path.join(act_dir, '%s.npy') %(act_dict_name ), allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unknown-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Condition information\n",
    "cond_list = np.array([[\"SM\", \"SC\"], [\"OM\", \"OC\"]])\n",
    "window_list = np.array([1,2,3,4,5,6,7,8])\n",
    "roi_list = ['dmPFC', 'rTPJ']\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "associate-lease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SM' 'SC']\n",
      "SM_SC_dmPFC_win1\n",
      "begin perm\n",
      "\n",
      " FOLD 0\n",
      " Train indices count: 21\n",
      " Test indices count: 6\n",
      "percent 1s of Y set 0.5761904761904761\n",
      "BEST C: 10\n",
      "inner score:  0.7212830782924242\n",
      "inner roc: 0.6709732634966279\n",
      "test predictions: [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0.]\n",
      "Outer score:  0.5 roc: 0.4992571269384343\n",
      "\n",
      " FOLD 1\n",
      " Train indices count: 21\n",
      " Test indices count: 6\n",
      "percent 1s of Y set 0.5891089108910891\n",
      "BEST C: 1e-05\n",
      "inner score:  0.5819230589069788\n",
      "inner roc: 0.5\n",
      "test predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Outer score:  0.41089108910891087 roc: 0.5\n",
      "\n",
      " FOLD 2\n",
      " Train indices count: 22\n",
      " Test indices count: 5\n",
      "percent 1s of Y set 0.6368421052631579\n",
      "BEST C: 1e-05\n",
      "inner score:  0.5764944732686668\n",
      "inner roc: 0.5\n",
      "test predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Outer score:  0.6368421052631579 roc: 0.5\n",
      "\n",
      " FOLD 3\n",
      " Train indices count: 22\n",
      " Test indices count: 5\n",
      "percent 1s of Y set 0.5260416666666666\n",
      "BEST C: 1e-05\n",
      "inner score:  0.5846823956442831\n",
      "inner roc: 0.5\n",
      "test predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Outer score:  0.4739583333333333 roc: 0.5\n",
      "\n",
      " FOLD 4\n",
      " Train indices count: 22\n",
      " Test indices count: 5\n",
      "percent 1s of Y set 0.59375\n",
      "BEST C: 1e-05\n",
      "inner score:  0.5918674698795181\n",
      "inner roc: 0.5\n",
      "test predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Outer score:  0.40625 roc: 0.5\n",
      "0.48558830554108046 0.4998514253876868\n",
      "end perm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'perm_dict_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dcdb34d3b091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Save perm array ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s_%s.npy'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_dict_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m## load ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perm_dict_name' is not defined"
     ]
    }
   ],
   "source": [
    "for roi in roi_list:\n",
    "    for cond_pair in cond_list:\n",
    "        print(cond_pair)\n",
    "        cond_a = cond_pair[0]\n",
    "        cond_b = cond_pair[1]\n",
    "        for window in window_list:\n",
    "            # name of current analysis\n",
    "            analysis = '%s_%s_%s_win%s' %(cond_a, cond_b, roi, window)\n",
    "            print(analysis)\n",
    "            X = activations[analysis]['X']\n",
    "            y = activations[analysis]['y']\n",
    "            groups = activations[analysis]['groups']\n",
    "            \n",
    "            ## Run analysis ##\n",
    "            permOuter_acc, permOuter_roc = single_perm(clf_GroupKFold_roc, X, y, groups, n_splits)\n",
    "            \n",
    "            # Save perm array ## \n",
    "            if os.path.isfile(os.path.join(perm_results, '%s_%s.npy') %(perm_roc_name, analysis)):\n",
    "                print('exists!')\n",
    "                ## load ## \n",
    "                perm_roc_arr = np.load(os.path.join(perm_results, '%s_%s.npy') % (perm_roc_name, analysis), allow_pickle=True)\n",
    "                ## update \n",
    "                perm_roc_arr = np.hstack((perm_roc_arr, permOuter_roc))\n",
    "                ## save ## \n",
    "                np.save(os.path.join(perm_results, '%s_%s.npy') %(perm_roc_name, analysis), perm_roc_arr)\n",
    "                print('saved')\n",
    "            else:\n",
    "                ## create roc \n",
    "                perm_roc_arr = np.hstack((np.array([]), permOuter_roc))\n",
    "                ## save \n",
    "                np.save(os.path.join(perm_results, '%s_%s.npy') %(perm_roc_name, analysis), perm_roc_arr)\n",
    "                print('creating dic')\n",
    "            print(f'finish {window}')\n",
    "        print(f'finish {cond_pair}')\n",
    "    print(f'finish {roi}')\n",
    "print('finished permutation ', num_perm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-hobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-publisher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-thursday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-universal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "behavioral-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load array of permuted accs #\n",
    "#perm_acc_arr = np.load(os.path.join(perm_dir, '%s_%s.npy') %(perm_dict_name, analysis), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "inner-swift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_SC_dmPFC_win4 is 0.5077173519206644 and roc is 0.5060661576845285\n",
      "SM_SC_dmPFC_win1 is 0.499146427330703 and roc is 0.5089558770046575\n",
      "SM_SC_dmPFC_win2 is 0.4846970613414725 and roc is 0.497487593707106\n",
      "SM_SC_dmPFC_win3 is 0.5725641875856811 and roc is 0.5543061760086928\n",
      "SM_SC_dmPFC_win5 is 0.4701257262386707 and roc is 0.4935494731310405\n",
      "SM_SC_dmPFC_win6 is 0.4330790195821456 and roc is 0.48999688473520253\n",
      "SM_SC_dmPFC_win7 is 0.48687761214320713 and roc is 0.5046275843668347\n",
      "SM_SC_dmPFC_win8 is 0.5504642088045076 and roc is 0.5378655175664194\n",
      "OM_OC_dmPFC_win1 is 0.5563530848258467 and roc is 0.4966770508826584\n",
      "OM_OC_dmPFC_win2 is 0.5169152767864651 and roc is 0.4920126719738477\n",
      "OM_OC_dmPFC_win3 is 0.5332698222240444 and roc is 0.5277809982249654\n",
      "OM_OC_dmPFC_win4 is 0.5528969986656052 and roc is 0.5409648483072947\n",
      "OM_OC_dmPFC_win5 is 0.5379991092901042 and roc is 0.5041198016230776\n",
      "OM_OC_dmPFC_win6 is 0.5206565278857747 and roc is 0.48982330917154754\n",
      "OM_OC_dmPFC_win7 is 0.5323972977314405 and roc is 0.5083374004358515\n",
      "OM_OC_dmPFC_win8 is 0.5311680127146381 and roc is 0.5099492229178828\n",
      "SM_SC_rTPJ_win1 is 0.487640977443609 and roc is 0.4947606729314046\n",
      "SM_SC_rTPJ_win2 is 0.4919842769051341 and roc is 0.49823073945025165\n",
      "SM_SC_rTPJ_win3 is 0.5623862174077109 and roc is 0.5300279955520102\n",
      "SM_SC_rTPJ_win4 is 0.5374759808797501 and roc is 0.5215997652871728\n",
      "SM_SC_rTPJ_win5 is 0.499244478124521 and roc is 0.5104693987461579\n"
     ]
    }
   ],
   "source": [
    "## scoring not equal to roc_auc in neseted cross validation ##\n",
    "\n",
    "#acc_dict_name = f'classification_acc_n28roc_{date}'\n",
    "\n",
    "#accuracies = np.load(os.path.join(acc_dir, '%s.npy') %(acc_dict_name ), allow_pickle=True).item()\n",
    "for anal in accuracies:\n",
    "    print(f'{anal} is {accuracies[anal][\"OutAcc\"]} and roc is {accuracies[anal][\"roc\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-conducting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
